{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d353d2eb-a564-4b8c-a56d-78154f7683b1",
   "metadata": {},
   "source": [
    "## BioGPT: Biomedical Text vs Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "155658e8-34d4-4423-92c4-8243d03367da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba90b72b-0408-4108-a600-7a02d19cbe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path and load model\n",
    "model_path = \"/mnt/liuzq/modelscope_cache/models/xw-download/AIModel/microsoft/biogpt\"\n",
    "snapshots_path = os.path.join(model_path, \"snapshots\")\n",
    "snapshot_dir = os.listdir(snapshots_path)[0]\n",
    "real_model_path = os.path.join(snapshots_path, snapshot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1599b2d-2ff9-4258-9569-c4d3f7645fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "tokenizer = AutoTokenizer.from_pretrained(real_model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(real_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1355e90-feee-4a3f-aa02-107170b2e900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: COVID-19 is\n",
      "Output: COVID-19 is a global pandemic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test biomedical question\n",
    "prompt1 = \"COVID-19 is\"\n",
    "inputs1 = tokenizer(prompt1, return_tensors=\"pt\")\n",
    "outputs1 = model.generate(**inputs1, max_length=10000, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "result1 = tokenizer.decode(outputs1[0], skip_special_tokens=True)\n",
    "print(f\"Prompt: {prompt1}\")\n",
    "print(f\"Output: {result1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da99439f-72fd-494d-8e9a-4c2563616f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Write R code for differential expression analysis using limma package\n",
      "Output: Write R code for differential expression analysis using limma package.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test code generation\n",
    "prompt2 = \"Write R code for differential expression analysis using limma package\"\n",
    "inputs2 = tokenizer(prompt2, return_tensors=\"pt\")\n",
    "outputs2 = model.generate(**inputs2, max_length=10000, num_return_sequences=1, do_sample=True, top_p=0.95, temperature=0.8, pad_token_id=tokenizer.eos_token_id)\n",
    "result2 = tokenizer.decode(outputs2[0], skip_special_tokens=True)\n",
    "print(f\"Prompt: {prompt2}\")\n",
    "print(f\"Output: {result2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2843024b-bac6-477f-9cef-906306dc1123",
   "metadata": {},
   "source": [
    "## BioMistral: Biomedical Text vs Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e696d455-50f0-4f90-81ef-b23696c96053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model path\n",
    "model_path = \"/mnt/liuzq/modelscope_cache/models/xw-download/AIModel/BioMistral/BioMistral-7B/snapshots/9a11e1ffa817c211cbb52ee1fb312dc6b61b40a5/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48eb69fd-1811-44db-a1f7-f160bd11a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8435df1-852d-425b-b358-a7fbd68fca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: COVID-19 is\n",
      "Output: COVID-19 is a novel coronavirus that was first identified in December 2019 in Wuhan, China. It is a highly infectious disease that has spread rapidly around the world. The World Health Organization (WHO) declared COVID-19 a pandemic on 11 March 2020. As of 15 June 2020, there have been 7,800,000 confirmed cases and 430,000 deaths worldwide .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test biomedical question\n",
    "prompt1 = \"COVID-19 is\"\n",
    "inputs1 = tokenizer(prompt1, return_tensors=\"pt\").to(model.device)\n",
    "outputs1 = model.generate(**inputs1, max_length=10000, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "result1 = tokenizer.decode(outputs1[0], skip_special_tokens=True)\n",
    "print(f\"Prompt: {prompt1}\")\n",
    "print(f\"Output: {result1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3ad0a93-c3c6-45d3-b3bd-c562483fb983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Write R code for differential expression analysis using limma package\n",
      "Output: Write R code for differential expression analysis using limma package. Note the difference between the limma design matrix in this example and the design matrixes in examples 2 and 3. In example 2 and 3, a column of the design matrix was used to indicate the factor of interest for each sample, while in this example, a row of the design matrix is used to indicate the factor of interest for each gene.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test code generation\n",
    "prompt2 = \"Write R code for differential expression analysis using limma package\"\n",
    "inputs2 = tokenizer(prompt2, return_tensors=\"pt\").to(model.device)\n",
    "outputs2 = model.generate(**inputs2, max_length=10000, num_return_sequences=1, do_sample=True, top_p=0.95, temperature=0.8, pad_token_id=tokenizer.eos_token_id)\n",
    "result2 = tokenizer.decode(outputs2[0], skip_special_tokens=True)\n",
    "print(f\"Prompt: {prompt2}\")\n",
    "print(f\"Output: {result2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29cfd75-0222-40fc-8a92-2013b1b9c323",
   "metadata": {},
   "source": [
    "## BioMedLM: Biomedical Text vs Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd9c3e70-a4db-4d11-aadc-0d29b3c7c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/mnt/liuzq/modelscope_cache/models/xw-download/AIModel/stanford-crfm/-BioMedLM/snapshots/3e1a0abb814b8398bc34b4b6680ecf2c26d6a66f/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d1a9157-c7eb-4e7d-b5cd-aa7583d20742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5813895-a4fd-4d16-ab48-219a31d43fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: COVID-19 is\n",
      "Output: COVID-19 is a novel coronavirus, the virus is a major cause of the disease.\n",
      "\n",
      "The authors declare no competing interests.\n",
      "\n",
      "Author contributions {#s0010}\n",
      "=========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test biomedical question\n",
    "prompt1 = \"COVID-19 is\"\n",
    "inputs1 = tokenizer(prompt1, return_tensors=\"pt\")\n",
    "outputs1 = model.generate(**inputs1, max_length=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "result1 = tokenizer.decode(outputs1[0], skip_special_tokens=True)\n",
    "print(f\"Prompt: {prompt1}\")\n",
    "print(f\"Output: {result1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f016d0f-9a8c-471e-8663-103cdd335fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Write R code for differential expression analysis using limma package\n",
      "Output: Write R code for differential expression analysis using limma package (see the [Supplementary Materials and methods. A total of 25,432 of the 25,432 (16.9%) of the 144 total genes were shared between the two datasets (see [Figure 4---figure supplement 4](#SD1){ref-type=\"supplementary-material\"}.\n",
      "\n",
      "              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test code generation\n",
    "prompt2 = \"Write R code for differential expression analysis using limma package\"\n",
    "inputs2 = tokenizer(prompt2, return_tensors=\"pt\")\n",
    "outputs2 = model.generate(**inputs2, max_length=100, num_return_sequences=1, do_sample=True, top_p=0.95, temperature=0.8, pad_token_id=tokenizer.eos_token_id)\n",
    "result2 = tokenizer.decode(outputs2[0], skip_special_tokens=True)\n",
    "print(f\"Prompt: {prompt2}\")\n",
    "print(f\"Output: {result2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dac645-7389-4100-b70b-2ad03738d8c3",
   "metadata": {},
   "source": [
    "## Bio-Medical-Llama: Biomedical Text vs Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6593d03-5d4d-4fdb-90b5-8476a1255956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model path\n",
    "base_path = \"/mnt/liuzq/modelscope_cache/models/xw-download/AIModel2/models--mlfoundations-dev--stackexchange_bioinformatics\"\n",
    "snapshots_path = os.path.join(base_path, \"snapshots\")\n",
    "snapshot_dir = os.listdir(snapshots_path)[0]\n",
    "model_path = os.path.join(snapshots_path, snapshot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7c39c93-4966-46f8-a6c2-0e5890274b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4acafc7b5c4633b4c3e26d75015235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89cd9854-3b0a-4134-a102-6ba31dd34fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae9d8033-3a8c-4f29-9afb-38dd42669ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/liuzq/conda_envs/myenv/lib/python3.10/site-packages/transformers/generation/utils.py:2347: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: COVID-19 is\n",
      "Output: COVID-19 is a new disease, caused by a novel (or new) coronavirus that has not previously been seen in humans. Itâ€™s been discovered in Wuhan, China. The virus is thought to spread mainly from person-to-person. Between people who are in close contact with one another (within about 6 feet). Through respiratory droplets produced when an infected person coughs or sneezes. These droplets can land in the mouths or noses of people who are nearby or possibly be\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test biomedical question\n",
    "prompt1 = \"COVID-19 is\"\n",
    "inputs1 = tokenizer(prompt1, return_tensors=\"pt\")\n",
    "outputs1 = model.generate(**inputs1, max_length=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "result1 = tokenizer.decode(outputs1[0], skip_special_tokens=True)\n",
    "print(f\"Prompt: {prompt1}\")\n",
    "print(f\"Output: {result1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a29346b2-a764-4f6f-b630-dc4a016c7d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Write R code for differential expression analysis using limma package\n",
      "Output: Write R code for differential expression analysis using limma package\n",
      "\n",
      "Differential expression analysis is a fundamental task in bioinformatics, especially when analyzing RNA-Seq data. The `limma` package in R is widely used for this purpose because of its robustness and flexibility. In this tutorial, we'll guide you through writing R code for differential expression analysis using the `limma` package.\n",
      "\n",
      "### Step 1: Install and Load the Required Packages\n",
      "Make sure you have the `limma` and `edgeR` packages installed. If not, you can install them using the following commands:\n",
      "\n",
      "```R\n",
      "install.packages(\"BiocManager\")\n",
      "BiocManager::install(\"limma\")\n",
      "```\n",
      "\n",
      "Now load the necessary libraries:\n",
      "\n",
      "```R\n",
      "library(limma)\n",
      "library(edgeR)\n",
      "```\n",
      "\n",
      "### Step 2: Prepare Your Count Data\n",
      "You need to prepare your count data in a matrix format, where rows are genes and columns are samples. The data should be in a count format (e.g., number of reads per gene per sample).\n",
      "\n",
      "### Step 3: Create an EdgeR Count Matrix\n",
      "Assuming you have a data frame named `countData` with counts, you can convert it into an `DGEList` object. Hereâ€™s an example of how to do that:\n",
      "\n",
      "```R\n",
      "# Example count data\n",
      "countData <- as.matrix(read.table(\"path/to/your/count_data.txt\", header = TRUE, row.names = 1))\n",
      "\n",
      "# Create a DGEList object\n",
      "dge <- DGEList(counts = countData)\n",
      "```\n",
      "\n",
      "### Step 4: Filter Lowly Expressed Genes\n",
      "Filter out genes that have low counts across samples. You can apply a threshold based on the mean or variance of the counts:\n",
      "\n",
      "```R\n",
      "# Filter out lowly expressed genes\n",
      "dge <- filterByExpr(dge)\n",
      "```\n",
      "\n",
      "### Step 5: Create a Design Matrix\n",
      "You need to create a design matrix that specifies the experimental conditions. Here's an example for a two-group comparison:\n",
      "\n",
      "```R\n",
      "# Example design matrix (assuming two groups)\n",
      "design <- model.matrix(~ 0 + factor(c(\"Group1\", \"Group2\")), data = dge)\n",
      "colnames(design) <- c(\"Group1\", \"Group2\")\n",
      "```\n",
      "\n",
      "### Step 6: Estimate Dispersion\n",
      "Estimate the dispersion for the model:\n",
      "\n",
      "```R\n",
      "dge <- estimateDisp(dge, design)\n",
      "```\n",
      "\n",
      "### Step 7: Fit the Linear Model\n",
      "Fit the linear model to the data:\n",
      "\n",
      "```R\n",
      "fit <- glmFit(dge, design)\n",
      "```\n",
      "\n",
      "### Step 8: Perform Differential Expression Analysis\n",
      "Perform differential expression analysis using `limma`:\n",
      "\n",
      "```R\n",
      "results <- glmLRT(fit, coef=2)  # Assuming the second coefficient is the contrast of interest\n",
      "```\n",
      "\n",
      "### Step 9: Adjust for Multiple Testing\n",
      "Adjust p-values for multiple testing using the Benjamini-Hochberg method:\n",
      "\n",
      "```R\n",
      "results <- topTable(results, adjust = \"BH\")\n",
      "```\n",
      "\n",
      "### Step 10: Extract Results\n",
      "Extract the results, including log-fold changes and adjusted p-values:\n",
      "\n",
      "```R\n",
      "results <- results[order(results$P.Value), ]\n",
      "```\n",
      "\n",
      "### Step 11: Visualize Results\n",
      "You can visualize the results using a volcano plot or heatmap. For example:\n",
      "\n",
      "```R\n",
      "library(ggplot2)\n",
      "\n",
      "# Volcano plot\n",
      "ggplot(results, aes(x=logFC, y=-log10(P.Value))) +\n",
      "  geom_point(aes(color=adj.P.Val < 0.05)) +\n",
      "  scale_color_manual(values = c(\"black\", \"red\")) +\n",
      "  theme_minimal() +\n",
      "  labs(title = \"Volcano Plot of Differential Expression\",\n",
      "       x = \"Log2 Fold Change\",\n",
      "       y = \"-Log10 Adjusted P Value\") +\n",
      "  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n",
      "```\n",
      "\n",
      "### Summary\n",
      "This code provides a comprehensive framework for differential expression analysis using the `limma` package. Adjust the parameters and data paths according to your specific analysis needs. Make sure to replace the example data with your actual count data for meaningful results. \n",
      "\n",
      "Feel free to modify or extend the code as necessary for your analysis! \n",
      "\n",
      "### Conclusion\n",
      "Now you have the basic tools to perform differential expression analysis using the `limma` package in R. With practice, you can customize this workflow to analyze more complex datasets or scenarios in your research. \n",
      "\n",
      "Feel free to ask questions or reach out for further assistance! \n",
      "\n",
      "```R\n",
      "# Example data generation\n",
      "set.seed(123)\n",
      "n <- 100  # number of genes\n",
      "k <- 20   # number of samples\n",
      "group <- factor(c(rep(\"Group1\", k/2), rep(\"Group2\", k/2)))\n",
      "\n",
      "# Simulate count data\n",
      "countData <- matrix(rpois(n * k, lambda = 5), nrow=n, ncol=k)\n",
      "rownames(countData) <- paste(\"Gene\", 1:n, sep=\"_\")\n",
      "colnames(countData) <- paste(\"Sample\", 1:k, sep=\"_\")\n",
      "\n",
      "# Filter lowly expressed genes\n",
      "dge <- DGEList(counts = countData)\n",
      "dge <- filterByExpr(dge)\n",
      "\n",
      "# Create design matrix\n",
      "design <- model.matrix(~ 0 + factor(group), data = dge)\n",
      "colnames(design) <- c(\"Group1\", \"Group2\")\n",
      "\n",
      "# Fit the linear model\n",
      "fit <- glmFit(dge, design)\n",
      "\n",
      "# Perform differential expression analysis\n",
      "results <- glmLRT(fit, coef=2)\n",
      "results <- topTable(results, adjust = \"BH\")\n",
      "\n",
      "# Print the results\n",
      "print(results)\n",
      "```\n",
      "\n",
      "### Further Reading\n",
      "- For detailed explanations of the functions used in this code, refer to the `limma` and `edgeR` documentation: \n",
      "  - [limma documentation](https://bioconductor.org/packages/release/bioc/html/limma.html)\n",
      "  - [edgeR documentation](https://bioconductor.org/packages/release/bioc/html/edgeR.html)\n",
      "  \n",
      "- If you need to analyze more complex designs or datasets, consider looking into the `limma` documentation for options like `voom` for RNA-Seq data or for other experimental designs. \n",
      "\n",
      "This code provides a solid foundation for your analyses, and with practice, you'll be able to adapt it for your specific research questions! ðŸ“šðŸ¤“\n",
      "\n",
      "### Additional Considerations:\n",
      "- **Normalization**: Make sure to consider the normalization step if you're using raw counts from RNA-Seq. \n",
      "- **Batch Effects**: If applicable, consider handling batch effects when designing your experiment.\n",
      "- **Explore Other Packages**: If you're working with specific datasets or have unique requirements, consider exploring other packages such as `DESeq2` or `voom` for alternative methodologies. \n",
      "\n",
      "### Summary\n",
      "The code provided outlines a comprehensive workflow for differential expression analysis using the `limma` package in R. It is designed to be flexible and adaptable, and with further customization, you can apply it to a variety of RNA-Seq analyses. Happy coding! ðŸ˜„\n",
      "\n",
      "### Sample Data:\n",
      "You can replace the simulated data with your own RNA-Seq count data. Make sure it is organized correctly in a matrix format. \n",
      "\n",
      "### Additional Resources:\n",
      "- **Bioconductor**: Visit the Bioconductor website for the latest documentation and resources on RNA-Seq analysis.\n",
      "- **RStudio**: Use RStudio for a more interactive development environment for writing and testing R code. \n",
      "\n",
      "This concludes our tutorial on differential expression analysis using the `limma` package in R. If you have any questions or need further guidance, feel free to ask! ðŸ‘‹\n",
      "\n",
      "```R\n",
      "# Example data generation\n",
      "set.seed(123)\n",
      "n <- 100  # number of genes\n",
      "k <- 20   # number of samples\n",
      "group <- factor(c(rep(\"Group1\", k/2), rep(\"Group2\", k/2)))\n",
      "\n",
      "# Simulate count data\n",
      "countData <- matrix(rpois(n * k, lambda = 5), nrow=n, ncol=k)\n",
      "rownames(countData) <- paste(\"Gene\", 1:n, sep=\"_\")\n",
      "colnames(countData) <- paste(\"Sample\", 1:k, sep=\"_\")\n",
      "\n",
      "# Filter lowly expressed genes\n",
      "dge <- DGEList(counts = countData)\n",
      "dge <- filterByExpr(dge)\n",
      "\n",
      "# Create design matrix\n",
      "design <- model.matrix(~ 0 + factor(group), data = dge)\n",
      "colnames(design) <- c(\"Group1\", \"Group2\")\n",
      "\n",
      "# Fit the linear model\n",
      "fit <- glmFit(dge, design)\n",
      "\n",
      "# Perform differential expression analysis\n",
      "results <- glmLRT(fit, coef=2)\n",
      "results <- topTable(results, adjust = \"BH\")\n",
      "\n",
      "# Print the results\n",
      "print(results)\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test code generation\n",
    "prompt2 = \"Write R code for differential expression analysis using limma package\"\n",
    "inputs2 = tokenizer(prompt2, return_tensors=\"pt\")\n",
    "outputs2 = model.generate(**inputs2, max_length=10000, num_return_sequences=1, do_sample=True, top_p=0.95, temperature=0.8, pad_token_id=tokenizer.eos_token_id)\n",
    "result2 = tokenizer.decode(outputs2[0], skip_special_tokens=True)\n",
    "print(f\"Prompt: {prompt2}\")\n",
    "print(f\"Output: {result2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e797bc8-4ad4-4618-a830-9fd8f0a5fdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
